# PreProcessIR
Pre-Processing for an Information Retrieval System coded as part of a course on Computer Algorithms.

Information retrieval (IR) systems are a key part of modern computer science. IR systems are applied in situations where it would be necessary to search for relevant information from a collection of resources. For example, a web search engine would be an application of an IR system. The goal of this project is to create a program to tackle some of the pre­processing steps that a collection of resources must undergo before it can be effectively used by an IR system. These pre­processing steps include stop­word removal and stemming, which serve to reduce the variation of the textual data as much as possible. In this project we will perform stop­word removal and stemming on 40 different text files consisting of raw data from web pages. Certain words in the English language are considered “stop words” because they are not useful in terms of interpreting the utterance of the text. Due to their limited utility, these words should be removed from the documents. The idea of stemming is to consolidate words with similar roots such that all words sharing the same root are replaced with their stem. A stem may not necessarily be the morphological root, but simply a common identifier between words. While the effectiveness of stemming is believed to be limited in IR systems [1], stemmers are still common elements in web search engines and therefore a valid pre­processing step.
Before the stop words can be removed from each text file, it is important to remove other extraneous characters from the files. Since the data in the text files is raw data from web pages, there are certain characters and words that are not a part of the english language, as well as numbers, source reference notations, and punctuation. These elements are not relevant to our IR
Briana Lamet Daniel Atadan Cisc320: Project 2
 system and therefore must be removed. Using C++, we created the functions m akesets and c lean which serve to read in each of the text files, remove unwanted elements, and return the desired elements as a set of strings. We read in the text files by words rather than by lines because it automatically splits the text file over spaces, which we would otherwise have to remove. Each word string is run through the c lean function, which takes in a string and returns a set of strings. The function removes all punctuation, numbers, and other non­alphabet characters. For consistency, all characters are cast to lowercase. Characters encapsulated by forward slashes are webpage noise and therefore removed. Characters surrounded by brackets are references to sources and are also removed. Words that contain a hyphen are separated into different words and returned as a set of those words. For example “species­rich” would become the set {“species”,”rich”}. Within the m akesets function, each word of the set that is returned from the clean function is then added to an overall set of strings representing the text file.
Once the text file has been cleaned and processed into a set of strings containing the relevant words from the original text file, we can then remove the stop words from this set. After creating a string set containing the words from the stop words file, removing them from the text is as simple as taking the set difference. This is the main reason that we chose to use the data structure of string sets for our project. Set difference is a built­in function where given sets A and B, the operation (A ­ B) removes all words in set B from set A. Additionally, by storing the words of the text files in string sets it ensures that there are no duplicate elements because every element of a set must be unique.
After the stop words are removed from the text file, the remaining words of the string set must be run through a stemming algorithm. The stemming algorithm is designed to interpret the
 form of a word in English and determine if a suffix can be removed to get to a simpler form of the word. This involves shortening plural forms of words or verb conjugations. For example, a stemmer would identify the words “stemming”, “stemmer”, “stems”, “stemmed”, all based on the root word “stem”. Classifying words and terms in this way condenses the amount of information to be searched against a certain database when given an inquiry.
The code we worked on was based on an online solution to the stemming problem using the Porter Algorithm. The Porter Algorithm is a normalisation process for removing inflectional endings from words, usually when setting up IR systems. In theory, the code would have functions to check the number of consonant clusters, to call strings by reference and adjust them, and to check different endings of the word to alter it. Since a word could have multiple removable prefixes and suffixes, it is important to have multiple waves of checks and alterations based on the number of consonant vowel changes there are in the word.
Unfortunately, due to the time constraint of this project, we were unable to write a complete and working algorithm for word stemming. We found many examples of functioning code online that would stem a file by using character pointers. Many implementations of the Porter Stemming algorithm exist and are freely distributed, but these implementations may contain flaws and therefore do not operate at maximum potential. There is also an official implementation of the software released by its creator, Martin Porter, available online [3].
However, it would be academically dishonest to take working code from the web and tweak it to complete our own project. Our interpretation of this project is that the assignment was to create code for our own implementation of the Porter stemming algorithm. We attempted to write a stemming algorithm from scratch using these sources as reference, but our earlier choice
to organize the data as string sets made adapting existing algorithms a more daunting task than we anticipated. We developed an idea for how we would structure our algorithm, but we were not able to successfully code an operational version of it.
Fortunately, stemming in modern computer science is overall not a valuable function. Stemming is most valuable in situations when a language is highly inflective and when documents are short. However, most searches require sifting through large amounts of long documents which allows for larger memory allotments. The Porter stemmer in particular often under­stems words given its short list of rules and suffixes. It also is less precise and weaker than other stemmers that use more memory and provide more condensed outputs [2].
For the sake of the project, let’s assume that we had some sort of working stemming algorithm. After the stop words of each text file were removed and the irrelevant elements cleaned out, the resulting set of strings would be passed through to a stemming function. This stemming function would then implement the Porter stemming algorithm and return the stemmed version of the data. Lastly, the fully cleaned and stemmed version of the original data is saved into a new file called “corpus”. The collection of data or texts that an IR system uses is by convention called the “corpus”, so these cleaned versions of the texts can now move on to be used for searching and indexing to develop a knowledge base.
